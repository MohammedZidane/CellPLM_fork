{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92d8348",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd78ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy.sparse import csr_matrix\n",
    "from CellPLM.utils import set_seed\n",
    "from CellPLM.pipeline.cell_type_annotation import CellTypeAnnotationPipeline, CellTypeAnnotationDefaultPipelineConfig, CellTypeAnnotationDefaultModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70636150",
   "metadata": {},
   "source": [
    "## Specify important parameters before getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dcaeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'MS' # 'hPancreas'\n",
    "PRETRAIN_VERSION = '20230926_85M-Copy1'\n",
    "DEVICE = 'cuda:3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae3f08",
   "metadata": {},
   "source": [
    "## Load Downstream Dataset\n",
    "\n",
    "The MS dataset is contributed by [scGPT](https://github.com/bowang-lab/scGPT/blob/main/tutorials/Tutorial_Annotation.ipynb). hPancreas dataset is contributed by [TOSICA](https://github.com/JackieHanLab/TOSICA/blob/main/test/tutorial.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9946798",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "if DATASET == 'hPancreas':\n",
    "    data_train = ad.read_h5ad(f'../data/demo_train.h5ad')\n",
    "    data_test = ad.read_h5ad(f'../data/demo_test.h5ad')\n",
    "    train_num = data_train.shape[0]\n",
    "    data = ad.concat([data_train, data_test])\n",
    "    data.X = csr_matrix(data.X)\n",
    "    data.obs['celltype'] = data.obs['Celltype']\n",
    "\n",
    "elif DATASET == 'MS':\n",
    "    data_train = ad.read_h5ad(f'../data/c_data.h5ad')\n",
    "    data_test = ad.read_h5ad(f'../data/filtered_ms_adata.h5ad')\n",
    "    data_train.var = data_train.var.set_index('index_column')\n",
    "    data_test.var = data_test.var.set_index('index_column')\n",
    "    train_num = data_train.shape[0]\n",
    "    data = ad.concat([data_train, data_test])\n",
    "    data.var_names_make_unique()\n",
    "\n",
    "data.obs['split'] = 'test'\n",
    "tr = np.random.permutation(train_num) #torch.randperm(train_num).numpy()\n",
    "data.obs['split'][tr[:int(train_num*0.9)]] = 'train'\n",
    "data.obs['split'][tr[int(train_num*0.9):train_num]] = 'valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684541b5",
   "metadata": {},
   "source": [
    "## Overwrite parts of the default config\n",
    "These hyperparameters are recommended for general purpose. We did not tune it for individual datasets. You may update them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd852eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'es': 200,\n",
       "  'lr': 0.005,\n",
       "  'wd': 1e-07,\n",
       "  'scheduler': 'plat',\n",
       "  'epochs': 2000,\n",
       "  'max_eval_batch_size': 100000,\n",
       "  'hvg': 3000,\n",
       "  'patience': 25,\n",
       "  'workers': 0},\n",
       " {'drop_node_rate': 0.3,\n",
       "  'dec_layers': 1,\n",
       "  'model_dropout': 0.5,\n",
       "  'mask_node_rate': 0.75,\n",
       "  'mask_feature_rate': 0.25,\n",
       "  'dec_mod': 'mlp',\n",
       "  'latent_mod': 'ae',\n",
       "  'head_type': 'annotation',\n",
       "  'max_batch_size': 70000,\n",
       "  'out_dim': 18})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config = CellTypeAnnotationDefaultPipelineConfig.copy()\n",
    "\n",
    "model_config = CellTypeAnnotationDefaultModelConfig.copy()\n",
    "model_config['out_dim'] = data.obs['celltype'].nunique()\n",
    "pipeline_config, model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41f709",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c7b4c",
   "metadata": {},
   "source": [
    "Efficient data setup and fine-tuning can be seamlessly conducted using the CellPLM built-in `pipeline` module.\n",
    "\n",
    "First, initialize a `CellTypeAnnotationPipeline`. This pipeline will automatically load a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec03a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OmicsFormer(\n",
       "  (embedder): OmicsEmbeddingLayer(\n",
       "    (act): ReLU()\n",
       "    (norm0): GroupNorm(4, 1024, eps=1e-05, affine=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (extra_linear): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (pe_enc): Sinusoidal2dPE(\n",
       "      (pe_enc): Embedding(10000, 1024)\n",
       "    )\n",
       "    (feat_enc): OmicsEmbedder()\n",
       "  )\n",
       "  (mask_model): MaskBuilder()\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): FlowformerLayer(\n",
       "        (self_attn): Flow_Attention(\n",
       "          (query_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (value_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "        (_ff_block): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FlowformerLayer(\n",
       "        (self_attn): Flow_Attention(\n",
       "          (query_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (value_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "        (_ff_block): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): FlowformerLayer(\n",
       "        (self_attn): Flow_Attention(\n",
       "          (query_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (value_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "        (_ff_block): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): FlowformerLayer(\n",
       "        (self_attn): Flow_Attention(\n",
       "          (query_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (value_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "        (_ff_block): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (latent): LatentModel(\n",
       "    (layers): ModuleList(\n",
       "      (0): PlaceholderLayer()\n",
       "      (1): MergeLatentLayer(\n",
       "        (lat_2lat): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): AnnotationHead(\n",
       "    (ce_loss): CrossEntropyLoss()\n",
       "    (mlp): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=18, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pre_latent_norm): PreLatentNorm(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = CellTypeAnnotationPipeline(pretrain_prefix=PRETRAIN_VERSION, # Specify the pretrain checkpoint to load\n",
    "                                      overwrite_config=model_config,  # This is for overwriting part of the pretrain config\n",
    "                                      pretrain_directory='../ckpt')\n",
    "pipeline.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b84d82",
   "metadata": {},
   "source": [
    "Next, employ the `fit` function to fine-tune the model on your downstream dataset. This dataset should be in the form of an AnnData object, where `.X` is a csr_matrix, and `.obs` includes information for train-test splitting and cell type labels.\n",
    "\n",
    "Typically, a dataset containing approximately 20,000 cells can be trained in under 10 minutes using a V100 GPU card, with an expected GPU memory consumption of around 8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36a5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, 2763 genes remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dict.keys(): dict_keys(['coord', 'x_seq', 'celltype', 'loss_mask', 'label'])\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(data, # An AnnData object\n",
    "            pipeline_config, # The config dictionary we created previously, optional\n",
    "            split_field = 'split', #  Specify a column in .obs that contains split information\n",
    "            train_split = 'train',\n",
    "            valid_split = 'valid',\n",
    "            label_fields = ['celltype']) # Specify a column in .obs that contains cell type labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ae43d",
   "metadata": {},
   "source": [
    "## Inference and evaluation\n",
    "Once the pipeline has been fitted to the downstream datasets, performing inference or evaluation on new datasets can be easily accomplished using the built-in `predict` and `score` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(\n",
    "                data, # An AnnData object\n",
    "                pipeline_config, # The config dictionary we created previously, optional\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b06749",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(data, # An AnnData object\n",
    "                pipeline_config, # The config dictionary we created previously, optional\n",
    "                split_field = 'split', # Specify a column in .obs to specify train and valid split, optional\n",
    "                target_split = 'test', # Specify a target split to predict, optional\n",
    "                label_fields = ['celltype'])  # Specify a column in .obs that contains cell type labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480477a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
